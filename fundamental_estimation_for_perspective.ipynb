{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Estimation for Fundamental Matrix (Perspective)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamental matrixをnormalized estimationで求める手順のメモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_matches(img1, img2, pts1, pts2, flag=None, mode=\"horizontal\", thick=5):\n",
    "    if flag is None:\n",
    "        assert(pts1.shape[0] == pts2.shape[0] and pts1.shape[1] == pts2.shape[1] == 2)\n",
    "    else:\n",
    "        assert(pts1.shape[0] == pts2.shape[0] == len(flag) and pts1.shape[1] == pts2.shape[1] == 2)\n",
    "    assert(mode == \"horizontal\" or mode == \"vertical\")\n",
    "    \n",
    "    num_pts = pts1.shape[0]\n",
    "    rows1 = img1.shape[0]\n",
    "    cols1 = img1.shape[1]\n",
    "    rows2 = img2.shape[0]\n",
    "    cols2 = img2.shape[1]\n",
    "\n",
    "    if mode == \"horizontal\":\n",
    "        out_img = np.zeros((max([rows1, rows2]), cols1 + cols2, 3), dtype=\"uint8\")\n",
    "        out_img[:rows1, :cols1, :] = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "        out_img[:rows2, cols1:cols1 + cols2, :] = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "    elif mode == \"vertical\":\n",
    "        out_img = np.zeros((rows1 + rows2, max([cols1, cols2]), 3), dtype=\"uint8\")\n",
    "        out_img[:rows1, :cols1, :] = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "        out_img[rows1:rows1 + rows2, :cols1, :] = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    for i in range(num_pts):\n",
    "        if flag is not None and bool(flag[i]) == False:\n",
    "            continue\n",
    "        (x1, y1) = (pts1[i, 0], pts1[i, 1])\n",
    "        (x2, y2) = (pts2[i, 0], pts2[i, 1])\n",
    "\n",
    "        color = [random.randint(0, 255) for i in range(3)]\n",
    "\n",
    "        if mode == \"horizontal\":\n",
    "            cv2.circle(out_img, (int(x1), int(y1)), 4, color, 1)\n",
    "            cv2.circle(out_img, (int(x2) + cols1, int(y2)), 4, color, 1)\n",
    "            cv2.line(out_img, (int(x1), int(y1)), (int(x2) + cols1, int(y2)), color, thick)\n",
    "        elif mode == \"vertical\":\n",
    "            cv2.circle(out_img, (int(x1), int(y1)), 4, color, 1)\n",
    "            cv2.circle(out_img, (int(x2), int(y2) + rows1), 4, color, 1)\n",
    "            cv2.line(out_img, (int(x1), int(y1)), (int(x2), int(y2) + rows1), color, thick)\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"./images/perspective/1.JPG\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"./images/perspective/3.JPG\", cv2.IMREAD_GRAYSCALE)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17, 10))\n",
    "ax[0].imshow(img1, cmap=plt.get_cmap(\"gray\"))\n",
    "ax[1].imshow(img2, cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT/ORB/AKAZEで特徴点対応を推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = \"ORB\"\n",
    "if feature_type == \"SIFT\":\n",
    "    detector = cv2.xfeatures2d.SIFT_create()\n",
    "    lowe_ratio = 0.6\n",
    "    norm_type = cv2.NORM_L2\n",
    "elif feature_type == \"ORB\":\n",
    "    detector = cv2.ORB_create()\n",
    "    detector.setMaxFeatures(4000)\n",
    "    detector.setNLevels(8)\n",
    "    detector.setScaleFactor(1.2)\n",
    "    detector.setScoreType(cv2.ORB_FAST_SCORE)\n",
    "    detector.setWTA_K(2)\n",
    "    lowe_ratio = 0.8\n",
    "    norm_type = cv2.NORM_HAMMING\n",
    "elif feature_type == \"AKAZE\":\n",
    "    detector = cv2.AKAZE_create()\n",
    "    lowe_ratio = 0.8\n",
    "    norm_type = cv2.NORM_HAMMING\n",
    "else:\n",
    "    raise ValueError(\"Undefined feature type: {}\".format(feature_type))\n",
    "\n",
    "# 特徴点と特徴量を抽出\n",
    "kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "# 第2近傍点まで探索する (k=2)\n",
    "bf = cv2.BFMatcher(norm_type)\n",
    "matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "# loweのratio testを行う\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < lowe_ratio * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# good matchのみ取り出す\n",
    "pts1 = [[kp1[m.queryIdx].pt[0], kp1[m.queryIdx].pt[1]] for m in good_matches]\n",
    "pts1 = np.array(pts1)\n",
    "pts2 = [[kp2[m.trainIdx].pt[0], kp2[m.trainIdx].pt[1]] for m in good_matches]\n",
    "pts2 = np.array(pts2)\n",
    "\n",
    "# 表示\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2), cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCVでFundamental matrixを推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, inliers = cv2.findFundamentalMat(pts1, pts2, method=cv2.RANSAC, ransacReprojThreshold=(1.0 * np.sqrt(3.841)))\n",
    "print(F)\n",
    "print(\"inlier ratio: {} / {} = {}\".format(np.count_nonzero(inliers), len(good_matches), np.count_nonzero(inliers) / len(good_matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2, inliers), cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalized estimationでFundamental matrixを推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考: https://www.peterkovesi.com/matlabfns/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原点を特徴点点群の重心に持っていき，重心から各対応点までの平均距離を$\\sqrt{2}$にする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(pts):\n",
    "    assert(pts.ndim == 2 and (pts.shape[1] == 2 or pts.shape[1] == 3))\n",
    "    # 同次座標にしておく\n",
    "    if pts.shape[1] == 2:\n",
    "        pts = np.insert(pts, 2, 1, axis=1)\n",
    "    # 返却値を用意\n",
    "    normalized_pts = np.ones(shape=(pts.shape[0], 3))\n",
    "    # 重心を計算\n",
    "    centoroid = np.mean(pts, axis=0)\n",
    "    # 重心を中心に持ってくる\n",
    "    normalized_pts[:, 0] = pts[:, 0] - centoroid[0]\n",
    "    normalized_pts[:, 1] = pts[:, 1] - centoroid[1]\n",
    "    # 中心からの各点の距離を計算\n",
    "    dists = np.sqrt(normalized_pts[:, 0] ** 2 + normalized_pts[:, 1] ** 2)\n",
    "    # 平均をsart(2)にするscaleを計算\n",
    "    scale = np.sqrt(2) / np.mean(dists)\n",
    "    # transformationを計算\n",
    "    transformation = np.array([[scale, 0, -scale * centoroid[0]],\n",
    "                               [0, scale, -scale * centoroid[1]],\n",
    "                               [0, 0, 1]])\n",
    "    # 座標変換\n",
    "    normalized_pts = transformation.dot(pts.T).T\n",
    "    return normalized_pts, transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DLTでFundamental matrixを求める．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fundamental_DLT(pts1, pts2):\n",
    "    assert(pts1.shape == pts2.shape)\n",
    "    num_pts = pts1.shape[0]\n",
    "    assert(8 <= num_pts)\n",
    "    # 行列Aを作成\n",
    "    A = np.zeros(shape=(num_pts, 9))\n",
    "    A[:, 0] = pts1[:, 0] * pts2[:, 0]\n",
    "    A[:, 1] = pts1[:, 1] * pts2[:, 0]\n",
    "    A[:, 2] = pts1[:, 2] * pts2[:, 0]\n",
    "    A[:, 3] = pts1[:, 0] * pts2[:, 1]\n",
    "    A[:, 4] = pts1[:, 1] * pts2[:, 1]\n",
    "    A[:, 5] = pts1[:, 2] * pts2[:, 1]\n",
    "    A[:, 6] = pts1[:, 0] * pts2[:, 2]\n",
    "    A[:, 7] = pts1[:, 1] * pts2[:, 2]\n",
    "    A[:, 8] = pts1[:, 2] * pts2[:, 2]\n",
    "    # SVD\n",
    "    ## Sは固有値が降順に格納されている\n",
    "    ## Vは転置されているので，Vの各行が固有ベクトル\n",
    "    U, s, V = np.linalg.svd(A, full_matrices=True)\n",
    "    # 最小固有値の固有ベクトルを並び替えたものがFundamental matrix\n",
    "    F_pre = V[8, :].reshape((3, 3))\n",
    "    # rank(F_pre)=2であるため，F_preの最小固有値を0にした再推定で精度向上\n",
    "    U, s, V = np.linalg.svd(F_pre, full_matrices=True)\n",
    "    s[2] = 0\n",
    "    F = U.dot(np.diag(s)).dot(V)\n",
    "    # F[2, 2]が1になるように正規化\n",
    "    F /= F[2, 2]\n",
    "    return F\n",
    "\n",
    "def find_fundamental_normalized_DLT(pts1, pts2):\n",
    "    # 座標を正規化\n",
    "    normalized_pts1, T1 = normalize(pts1)\n",
    "    normalized_pts2, T2 = normalize(pts2)\n",
    "    # Fundamental matrixを求める\n",
    "    Fi = find_fundamental_DLT(normalized_pts1, normalized_pts2)\n",
    "    # 座標変換\n",
    "    F = T2.T.dot(Fi).dot(T1)\n",
    "    # F[2, 2]が1になるように正規化\n",
    "    F /= F[2, 2]\n",
    "    return F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fundamental Matrixの評価にはsymmetric transfer errorを用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_fundamental(F, pts1, pts2, sigma=1.0):\n",
    "    assert(pts1.shape == pts2.shape)\n",
    "    num_pts = pts1.shape[0]\n",
    "    # 自由度1のカイ2乗値がinlierの閾値になる\n",
    "    chi2_threshold = 3.841\n",
    "    # 同次座標に変換\n",
    "    if pts1.shape[1] == 2 and normalize:\n",
    "        pts1 = np.insert(pts1, 2, 1, axis=1)\n",
    "    if pts2.shape[1] == 2 and normalize:\n",
    "        pts2 = np.insert(pts2, 2, 1, axis=1)\n",
    "    # 画像1の特徴点にFをかけると，画像2上の直線になる (a1, b1, c1)\n",
    "    epilines_in_img2 = F.dot(pts1.T).T\n",
    "    # 画像2の特徴点にF.Tをかけると，画像1上の直線になる (a2, b2, c2)\n",
    "    epilines_in_img1 = F.T.dot(pts2.T).T\n",
    "    # 点と直線の距離を計算する\n",
    "    ## (a1*x2 + b1*y2 + c1*1)^2 / (a1*a1 + b1*b1)\n",
    "    dists2_in_img2 = np.sum(epilines_in_img2 * pts2, axis=1) ** 2\n",
    "    dists2_in_img2 /= (epilines_in_img2[:, 0] ** 2 + epilines_in_img2[:, 1] ** 2)\n",
    "    ## (a2*x1 + b2*y1 + c2*1)^2 / (a2*a2 + b2*b2)\n",
    "    dists2_in_img1 = np.sum(epilines_in_img1 * pts1, axis=1) ** 2\n",
    "    dists2_in_img1 /= (epilines_in_img1[:, 0] ** 2 + epilines_in_img1[:, 1] ** 2)\n",
    "    # 正規化する\n",
    "    dists2_in_img2 /= (sigma ** 2)\n",
    "    dists2_in_img1 /= (sigma ** 2)\n",
    "    # inlierを探す\n",
    "    ## カイ2乗値以下であればであればinlierとする\n",
    "    inliers_in_img2 = dists2_in_img2 <= chi2_threshold\n",
    "    inliers_in_img1 = dists2_in_img1 <= chi2_threshold\n",
    "    inliers = inliers_in_img2 & inliers_in_img1\n",
    "    # inlierのみでscoreを計算する\n",
    "    ## 正規化L2ノルムとカイ2乗値との差がスコアになる (高いほど良い)\n",
    "    score = 0\n",
    "    score += np.sum(chi2_threshold - dists2_in_img2[inliers_in_img2])\n",
    "    score += np.sum(chi2_threshold - dists2_in_img1[inliers_in_img1])\n",
    "    return score, inliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANSACでFundamental matrixを求める．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_fundamental_RANSAC(pts1, pts2, sigma=1.0, num_iterations=50):\n",
    "    assert(pts1.shape == pts2.shape)\n",
    "    num_pts = pts1.shape[0]\n",
    "    # RANSACを回す\n",
    "    best_score = 0\n",
    "    best_inliers = np.full(num_pts, False)\n",
    "    for _ in range(num_iterations):\n",
    "        # ランダム抽出\n",
    "        sample_indices = np.random.choice(num_pts, min(8, num_pts), False)\n",
    "        sample_pts1 = pts1[sample_indices, :]\n",
    "        sample_pts2 = pts2[sample_indices, :]\n",
    "        # サンプル点でFundamental matrixを求める\n",
    "        F = find_fundamental_normalized_DLT(sample_pts1, sample_pts2)\n",
    "        # scoreを計算\n",
    "        score, inliers = evaluate_fundamental(F, pts1, pts2, sigma)\n",
    "        # best modelを更新\n",
    "        ## 条件A: np.sum(best_inliers) < np.sum(inliers)\n",
    "        ## 条件B: best_score < score\n",
    "        if np.sum(best_inliers) < np.sum(inliers):\n",
    "            best_score = score\n",
    "            best_inliers = inliers\n",
    "    # inlierのみでFを推定\n",
    "    F = find_fundamental_normalized_DLT(pts1[best_inliers], pts2[best_inliers])\n",
    "    return F, best_inliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCVの関数と自作の関数で比較する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "F, inliers = cv2.findFundamentalMat(pts1, pts2, method=cv2.RANSAC, ransacReprojThreshold=(1.0 * np.sqrt(3.841)), confidence=0.9999)\n",
    "score, inliers = evaluate_fundamental(F, pts1, pts2, sigma=1.0)\n",
    "print(\"OpenCV\")\n",
    "print(F)\n",
    "print(\"score: {}, inlier ratio: {} / {} = {}\".format(score, np.sum(inliers), len(good_matches), np.sum(inliers) / len(good_matches)))\n",
    "print(\"\")\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2, inliers), cmap=plt.get_cmap(\"gray\"))\n",
    "\n",
    "F, inliers = find_fundamental_RANSAC(pts1, pts2, sigma=1.0, num_iterations=1000)\n",
    "score, inliers = evaluate_fundamental(F, pts1, pts2, sigma=1.0)\n",
    "print(\"mine\")\n",
    "print(F)\n",
    "print(\"score: {}, inlier ratio: {} / {} = {}\".format(score, np.sum(inliers), len(good_matches), np.sum(inliers) / len(good_matches)))\n",
    "print(\"\")\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2, inliers), cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
