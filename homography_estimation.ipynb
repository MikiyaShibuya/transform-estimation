{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalized Estimation for Homography Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homography matrixをnormalized estimationで求める手順のメモ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import cv2\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def draw_matches(img1, img2, pts1, pts2, flag=None, mode=\"horizontal\", thick=5):\n",
    "    if flag is None:\n",
    "        assert(pts1.shape[0] == pts2.shape[0] and pts1.shape[1] == pts2.shape[1] == 2)\n",
    "    else:\n",
    "        assert(pts1.shape[0] == pts2.shape[0] == len(flag) and pts1.shape[1] == pts2.shape[1] == 2)\n",
    "    assert(mode == \"horizontal\" or mode == \"vertical\")\n",
    "    \n",
    "    num_pts = pts1.shape[0]\n",
    "    rows1 = img1.shape[0]\n",
    "    cols1 = img1.shape[1]\n",
    "    rows2 = img2.shape[0]\n",
    "    cols2 = img2.shape[1]\n",
    "\n",
    "    if mode == \"horizontal\":\n",
    "        out_img = np.zeros((max([rows1, rows2]), cols1 + cols2, 3), dtype=\"uint8\")\n",
    "        out_img[:rows1, :cols1, :] = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "        out_img[:rows2, cols1:cols1 + cols2, :] = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "    elif mode == \"vertical\":\n",
    "        out_img = np.zeros((rows1 + rows2, max([cols1, cols2]), 3), dtype=\"uint8\")\n",
    "        out_img[:rows1, :cols1, :] = cv2.cvtColor(img1, cv2.COLOR_GRAY2RGB)\n",
    "        out_img[rows1:rows1 + rows2, :cols1, :] = cv2.cvtColor(img2, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "    for i in range(num_pts):\n",
    "        if flag is not None and bool(flag[i]) == False:\n",
    "            continue\n",
    "        (x1, y1) = (pts1[i, 0], pts1[i, 1])\n",
    "        (x2, y2) = (pts2[i, 0], pts2[i, 1])\n",
    "\n",
    "        color = [random.randint(0, 255) for i in range(3)]\n",
    "\n",
    "        if mode == \"horizontal\":\n",
    "            cv2.circle(out_img, (int(x1), int(y1)), 4, color, 1)\n",
    "            cv2.circle(out_img, (int(x2) + cols1, int(y2)), 4, color, 1)\n",
    "            cv2.line(out_img, (int(x1), int(y1)), (int(x2) + cols1, int(y2)), color, thick)\n",
    "        elif mode == \"vertical\":\n",
    "            cv2.circle(out_img, (int(x1), int(y1)), 4, color, 1)\n",
    "            cv2.circle(out_img, (int(x2), int(y2) + rows1), 4, color, 1)\n",
    "            cv2.line(out_img, (int(x1), int(y1)), (int(x2), int(y2) + rows1), color, thick)\n",
    "\n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "画像を読み込む"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"./images/perspective/1.JPG\", cv2.IMREAD_GRAYSCALE)\n",
    "img2 = cv2.imread(\"./images/perspective/3.JPG\", cv2.IMREAD_GRAYSCALE)\n",
    "fig, ax = plt.subplots(1, 2, figsize=(17, 10))\n",
    "ax[0].imshow(img1, cmap=plt.get_cmap(\"gray\"))\n",
    "ax[1].imshow(img2, cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SIFT/ORB/AKAZEで特徴点対応を推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_type = \"ORB\"\n",
    "if feature_type == \"SIFT\":\n",
    "    detector = cv2.xfeatures2d.SIFT_create()\n",
    "    lowe_ratio = 0.6\n",
    "    norm_type = cv2.NORM_L2\n",
    "elif feature_type == \"ORB\":\n",
    "    detector = cv2.ORB_create()\n",
    "    detector.setMaxFeatures(4000)\n",
    "    detector.setNLevels(8)\n",
    "    detector.setScaleFactor(1.2)\n",
    "    detector.setScoreType(cv2.ORB_FAST_SCORE)\n",
    "    detector.setWTA_K(2)\n",
    "    lowe_ratio = 0.8\n",
    "    norm_type = cv2.NORM_HAMMING\n",
    "elif feature_type == \"AKAZE\":\n",
    "    detector = cv2.AKAZE_create()\n",
    "    lowe_ratio = 0.8\n",
    "    norm_type = cv2.NORM_HAMMING\n",
    "else:\n",
    "    raise ValueError(\"Undefined feature type: {}\".format(feature_type))\n",
    "\n",
    "# 特徴点と特徴量を抽出\n",
    "kp1, desc1 = detector.detectAndCompute(img1, None)\n",
    "kp2, desc2 = detector.detectAndCompute(img2, None)\n",
    "\n",
    "# 第2近傍点まで探索する (k=2)\n",
    "bf = cv2.BFMatcher(norm_type)\n",
    "matches = bf.knnMatch(desc1, desc2, k=2)\n",
    "\n",
    "# loweのratio testを行う\n",
    "good_matches = []\n",
    "for m, n in matches:\n",
    "    if m.distance < lowe_ratio * n.distance:\n",
    "        good_matches.append(m)\n",
    "\n",
    "# good matchのみ取り出す\n",
    "pts1 = [[kp1[m.queryIdx].pt[0], kp1[m.queryIdx].pt[1]] for m in good_matches]\n",
    "pts1 = np.array(pts1)\n",
    "pts2 = [[kp2[m.trainIdx].pt[0], kp2[m.trainIdx].pt[1]] for m in good_matches]\n",
    "pts2 = np.array(pts2)\n",
    "\n",
    "# 表示\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2), cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenCVでHomography matrixを推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H, inliers = cv2.findHomography(pts1, pts2, method=cv2.RANSAC, ransacReprojThreshold=(1.0 * np.sqrt(5.99)))\n",
    "print(H)\n",
    "print(\"inlier ratio: {} / {} = {}\".format(np.count_nonzero(inliers), len(good_matches), np.count_nonzero(inliers) / len(good_matches)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2, inliers), cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## normalized estimationでHomography matrixを推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "参考: https://www.cs.ubc.ca/grads/resources/thesis/May09/Dubrofsky_Elan.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "原点を特徴点点群の重心に持っていき，重心から各対応点までの平均距離を$\\sqrt{2}$にする．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(pts):\n",
    "    assert(pts.ndim == 2 and (pts.shape[1] == 2 or pts.shape[1] == 3))\n",
    "    # 同次座標にしておく\n",
    "    if pts.shape[1] == 2:\n",
    "        pts = np.insert(pts, 2, 1, axis=1)\n",
    "    # 返却値を用意\n",
    "    normalized_pts = np.ones(shape=(pts.shape[0], 3))\n",
    "    # 重心を計算\n",
    "    centoroid = np.mean(pts, axis=0)\n",
    "    # 重心を中心に持ってくる\n",
    "    normalized_pts[:, 0] = pts[:, 0] - centoroid[0]\n",
    "    normalized_pts[:, 1] = pts[:, 1] - centoroid[1]\n",
    "    # 中心からの各点の距離を計算\n",
    "    dists = np.sqrt(normalized_pts[:, 0] ** 2 + normalized_pts[:, 1] ** 2)\n",
    "    # 平均をsart(2)にするscaleを計算\n",
    "    scale = np.sqrt(2) / np.mean(dists)\n",
    "    # transformationを計算\n",
    "    transformation = np.array([[scale, 0, -scale * centoroid[0]],\n",
    "                               [0, scale, -scale * centoroid[1]],\n",
    "                               [0, 0, 1]])\n",
    "    # 座標変換\n",
    "    normalized_pts = transformation.dot(pts.T).T\n",
    "    return normalized_pts, transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DLTでHomography matrixを求める．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_homography_DLT(pts1, pts2):\n",
    "    assert(pts1.shape == pts2.shape)\n",
    "    num_pts = pts1.shape[0]\n",
    "    assert(4 <= num_pts)\n",
    "    # 行列Aを作成\n",
    "    A = np.zeros(shape=(2 * num_pts, 9))\n",
    "    ## [u, v, 1]\n",
    "    A[:num_pts, 0:2] = pts1[:, 0:2]\n",
    "    A[:num_pts, 2] = np.ones(shape=(num_pts))\n",
    "    ## [-u, -v, -1]\n",
    "    A[-num_pts:, 3:5] = -pts1[:, 0:2]\n",
    "    A[-num_pts:, 5] = -np.ones(shape=(num_pts))\n",
    "    ## [-u * u', -v * u', -u']\n",
    "    A[:num_pts, 6] = -pts1[:, 0] * pts2[:, 0]\n",
    "    A[:num_pts, 7] = -pts1[:, 1] * pts2[:, 0]\n",
    "    A[:num_pts, 8] = -pts2[:, 0]\n",
    "    ## [u * v', v * v', v']\n",
    "    A[-num_pts:, 6] = pts1[:, 0] * pts2[:, 1]\n",
    "    A[-num_pts:, 7] = pts1[:, 1] * pts2[:, 1]\n",
    "    A[-num_pts:, 8] = pts2[:, 1]\n",
    "    # SVD\n",
    "    ## Sは固有値が降順に格納されている\n",
    "    ## Vは転置されているので，Vの各行が固有ベクトル\n",
    "    U, s, V = np.linalg.svd(A, full_matrices=True)\n",
    "    # 最小固有値の固有ベクトルを並び替えたものがHomography matrixになる\n",
    "    H = V[8, :].reshape((3, 3))\n",
    "    # H[2, 2]が1になるように正規化\n",
    "    H /= H[2, 2]\n",
    "    return H\n",
    "\n",
    "def find_homography_normalized_DLT(pts1, pts2):\n",
    "    # 座標を正規化\n",
    "    normalized_pts1, T1 = normalize(pts1)\n",
    "    normalized_pts2, T2 = normalize(pts2)\n",
    "    # DLTでHomography matrixを求める\n",
    "    Hi = find_homography_DLT(normalized_pts1, normalized_pts2)\n",
    "    # 座標変換\n",
    "    H = np.linalg.inv(T2).dot(Hi).dot(T1)\n",
    "    return H / H[2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homography Matrixの評価にはsymmetric transfer errorを用いる．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_homography(H, pts1, pts2, sigma=1.0):\n",
    "    assert(pts1.shape == pts2.shape)\n",
    "    num_pts = pts1.shape[0]\n",
    "    # 自由度2のカイ2乗値がinlierの閾値になる\n",
    "    chi2_threshold = 5.991\n",
    "    # 同次座標に変換\n",
    "    if pts1.shape[1] == 2:\n",
    "        pts1 = np.insert(pts1, 2, 1, axis=1)\n",
    "    if pts2.shape[1] == 2:\n",
    "        pts2 = np.insert(pts2, 2, 1, axis=1)\n",
    "    # 画像1の特徴点を画像2上に写像 (同次座標に戻しておく)\n",
    "    pts1_in_img2 = H.dot(pts1.T).T\n",
    "    pts1_in_img2[:, 0] /= pts1_in_img2[:, 2]\n",
    "    pts1_in_img2[:, 1] /= pts1_in_img2[:, 2]\n",
    "    pts1_in_img2[:, 2] /= pts1_in_img2[:, 2]\n",
    "    # 画像2の特徴点を画像1上に写像 (同次座標に戻しておく)\n",
    "    pts2_in_img1 = np.linalg.inv(H).dot(pts2.T).T\n",
    "    pts2_in_img1[:, 0] /= pts2_in_img1[:, 2]\n",
    "    pts2_in_img1[:, 1] /= pts2_in_img1[:, 2]\n",
    "    pts2_in_img1[:, 2] /= pts2_in_img1[:, 2]\n",
    "    # 写像された点と本来の点との正規化L2ノルムを計算する\n",
    "    dists2_in_img2 = np.linalg.norm((pts2[:, 0:2] - pts1_in_img2[:, 0:2]) / sigma, axis=1) ** 2\n",
    "    dists2_in_img1 = np.linalg.norm((pts1[:, 0:2] - pts2_in_img1[:, 0:2]) / sigma, axis=1) ** 2\n",
    "    # inlierを探す\n",
    "    ## カイ2乗値以下であればであればinlierとする\n",
    "    inliers_in_img2 = dists2_in_img2 <= chi2_threshold\n",
    "    inliers_in_img1 = dists2_in_img1 <= chi2_threshold\n",
    "    inliers = inliers_in_img2 & inliers_in_img1\n",
    "    # inlierのみでscoreを計算する\n",
    "    ## 正規化L2ノルムとカイ2乗値との差がスコアになる (高いほど良い)\n",
    "    score = 0\n",
    "    score += np.sum(chi2_threshold - dists2_in_img2[inliers_in_img2])\n",
    "    score += np.sum(chi2_threshold - dists2_in_img1[inliers_in_img1])\n",
    "    return score, inliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RANSACでHomography matrixを求める．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_homography_RANSAC(pts1, pts2, sigma=1.0, num_iterations=50):\n",
    "    assert(pts1.shape == pts2.shape)\n",
    "    num_pts = pts1.shape[0]\n",
    "    # RANSACを回す\n",
    "    best_score = 0\n",
    "    best_inliers = np.full(num_pts, False)\n",
    "    for _ in range(num_iterations):\n",
    "        # ランダム抽出\n",
    "        sample_indices = np.random.choice(num_pts, min(4, num_pts), False)\n",
    "        sample_pts1 = pts1[sample_indices, :]\n",
    "        sample_pts2 = pts2[sample_indices, :]\n",
    "        # サンプル点でHomography matrixを求める\n",
    "        H = find_homography_normalized_DLT(sample_pts1, sample_pts2)\n",
    "        # scoreを計算\n",
    "        score, inliers = evaluate_homography(H, pts1, pts2, sigma)\n",
    "        # best modelを更新\n",
    "        ## 条件A: np.sum(best_inliers) < np.sum(inliers)\n",
    "        ## 条件B: best_score < score\n",
    "        if np.sum(best_inliers) < np.sum(inliers):\n",
    "            best_score = score\n",
    "            best_inliers = inliers\n",
    "    # inlierのみでHを推定\n",
    "    H = find_homography_normalized_DLT(pts1[best_inliers], pts2[best_inliers])\n",
    "    return H, best_inliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OpenCVの関数と自作の関数で比較する．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "H, inliers = cv2.findHomography(pts1, pts2, method=cv2.RANSAC, ransacReprojThreshold=(1.0 * np.sqrt(5.991)), maxIters=200)\n",
    "score, inliers = evaluate_homography(H, pts1, pts2, sigma=1.0)\n",
    "print(\"OpenCV\")\n",
    "print(H)\n",
    "print(\"score: {}, inlier ratio: {} / {} = {}\".format(score, np.sum(inliers), len(good_matches), np.sum(inliers) / len(good_matches)))\n",
    "print(\"\")\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2, inliers), cmap=plt.get_cmap(\"gray\"))\n",
    "\n",
    "H, inliers = find_homography_RANSAC(pts1, pts2, sigma=1.0, num_iterations=200)\n",
    "score, inliers = evaluate_homography(H, pts1, pts2, sigma=1.0)\n",
    "print(\"mine\")\n",
    "print(H)\n",
    "print(\"score: {}, inlier ratio: {} / {} = {}\".format(score, np.sum(inliers), len(good_matches), np.sum(inliers) / len(good_matches)))\n",
    "print(\"\")\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.imshow(draw_matches(img1, img2, pts1, pts2, inliers), cmap=plt.get_cmap(\"gray\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
